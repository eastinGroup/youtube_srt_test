WEBVTT
Kind: captions
Language: zh-Hans

00:00:00.030 --> 00:00:03.870
我叫Edgar，我是Netflix的工程师，从事工具和

00:00:03.870 --> 00:00:09.450
基础设施，这些年来，容器的采用呈指数增长

00:00:09.450 --> 00:00:14.340
因此有必要进行大规模发行，而Netflix确实推出了多达3个

00:00:14.340 --> 00:00:19.140
每周有1百万个集装箱，因此需要创新的集装箱分布

00:00:19.140 --> 00:00:24.810
重要的是，这里的容器图像是什么？我有一个1/2图像，它由

00:00:24.810 --> 00:00:29.699
4层和一层，它只是文件和目录的存档，我可以

00:00:29.699 --> 00:00:32.340
从博士那里拆包。底部显示其内容

00:00:32.340 --> 00:00:39.210
和层以其内容的哈希命名，就像ipfs一键一样

00:00:39.210 --> 00:00:43.350
我们的见解是，我们实际上可以将包子的定义定义为一对-

00:00:43.350 --> 00:00:48.629
从我们如何下载它开始，一旦我知道它没有什么层成分图像

00:00:48.629 --> 00:00:53.340
其实很重要，因为我可以独立验证哈希值，因此我们

00:00:53.340 --> 00:01:00.870
可以将ipfs用作容器层的CDN，让我们先访问一下

00:01:00.870 --> 00:01:07.170
ipfs添加文件，因此ipfs中的大文件被分解为散列以进行摘要

00:01:07.170 --> 00:01:11.490
然后将其存储为自我描述的标识符，即C ID，然后哈希为

00:01:11.490 --> 00:01:17.040
一棵称为merkel标签的节点树，其根是ID的标识符

00:01:17.040 --> 00:01:20.970
文件返回到包子中每一层的容器中-我们实际上可以

00:01:20.970 --> 00:01:25.979
将其分解为块，然后使用根将ID转换为

00:01:25.979 --> 00:01:30.570
通过执行此操作，容器D可以理解的摘要格式

00:01:30.570 --> 00:01:36.420
纯净版本的Ubuntu，然后我们可以将IP FS插件用于容器D

00:01:36.420 --> 00:01:40.829
为了通过ipfs检索容器层以演示如何

00:01:40.829 --> 00:01:45.960
我将在ec2集群上分片对等映像，然后

00:01:45.960 --> 00:01:51.329
尝试下载它，以便分片，我们将把每一层分解成

00:01:51.329 --> 00:01:57.030
块，其中一些可能会重复，然后将它们分组为大约33％

00:01:57.030 --> 00:02:02.450
总大小，然后将其固定在广告总线上的ec2节点上

00:02:03.320 --> 00:02:10.920
所以在这里我在ec2上有三个简单的两个节点，然后我将检查IPS

00:02:10.920 --> 00:02:14.520
回购，我们发现我们大约有14 KB

00:02:14.520 --> 00:02:19.470
数据，现在我们可以做的是在整个群集中分片对等映像

00:02:19.470 --> 00:02:29.340
这样每个节点大约拥有33％的数据，然后当我们再次检查IPS时

00:02:29.340 --> 00:02:34.770
我们将看到它们大约有二十兆字节的数据，所以我们想要

00:02:34.770 --> 00:02:39.060
现在要做的是测量每个节点和网络接收100％所需的时间

00:02:39.060 --> 00:02:52.950
数据，让我们看看它是如何工作的，大约花了两秒钟

00:02:52.950 --> 00:02:59.220
使用Akamai CDN接近docker hub速度，我们现在跟踪ipfs大约有28

00:02:59.220 --> 00:03:03.240
兆，这是数据鸡的连续性，我们可以看到层确实存在

00:03:03.240 --> 00:03:08.040
在所有节点上使这个变得更有趣，我们如何扩大规模

00:03:08.040 --> 00:03:13.470
做实验，我们将服务器组的大小调整为50个节点，这是

00:03:13.470 --> 00:03:21.900
要花点时间，所以我们要跳过前面-完成了，现在我们有了

00:03:21.900 --> 00:03:28.050
50个节点，这意味着当我们缩短图像时，每个节点占图像的2％

00:03:28.050 --> 00:03:32.940
或每个文件有7个文件块，这是不现实的情况，但我们会看到

00:03:32.940 --> 00:03:35.360
怎么运作的

00:03:41.930 --> 00:03:44.750
因此，您会发现存在很多网络震颤，这会影响

00:03:44.750 --> 00:03:58.629
分布图像，所以我接下来大约要花11秒的时间

00:04:05.000 --> 00:04:09.290
因此，容器生态系统容器已经使用了内容可寻址存储

00:04:09.290 --> 00:04:13.460
所以它使ipfs很自然，我相信ipfs有很大的机会

00:04:13.460 --> 00:04:17.840
为了改善分布，我们只需要关注基准测试和性能

00:04:17.840 --> 00:04:23.870
进行调整，那么下一步是从懒惰的调查中得到的论文57种不同

00:04:23.870 --> 00:04:27.590
容器化的应用程序，发现只有大约6％的数据是

00:04:27.590 --> 00:04:32.660
实际使用的，所以实际上可以做的是通过保险丝包装容器文件系统

00:04:32.660 --> 00:04:37.400
然后我们实际上可以创建一个清单，用于序列化元数据

00:04:37.400 --> 00:04:42.440
对于这样的文件，我们可以启动一个容器文件系统

00:04:42.440 --> 00:04:46.190
您会知道毫秒，因为清单只有200 KB的比特率，并且

00:04:46.190 --> 00:04:50.510
然后按需实际通过相同的ipfs插件下载文件

00:04:50.510 --> 00:04:55.870
通过IP CS，这是我正在研究的项目，谢谢

00:04:55.870 --> 00:05:04.079
[掌声]

