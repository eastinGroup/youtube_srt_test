WEBVTT
Kind: captions
Language: zh-Hans

00:00:06.960 --> 00:00:10.060
[掌声]

00:00:24.019 --> 00:00:47.250
好的，大家好，大家好，欢迎来到IPA FS每周电话

00:00:47.250 --> 00:00:51.180
我们要了解我们委员会中正在发生的伟大事情

00:00:51.180 --> 00:01:01.350
我们今天正在建造的建筑，让我们来看一下，在开始之前，如果每个人都可以

00:01:01.350 --> 00:01:14.430
嗯，在此之前，如果每个人都可以填写我们的每周呼叫列表中的IP，那么

00:01:14.430 --> 00:01:20.189
如果您要打电话，只需将手柄放在与会者下方

00:01:20.189 --> 00:01:30.090
部分，我们今天没有任何公告，所以我们将开始主要

00:01:30.090 --> 00:01:35.280
演讲，但在我们开始之前，我要感谢奥利（Ollie）做笔记，谢谢

00:01:35.280 --> 00:01:37.549
你奥利

00:01:37.939 --> 00:01:47.790
今天的主要主持人是迈克尔·罗杰斯（Michael Rogers），他将谈论

00:01:47.790 --> 00:01:53.880
github生态系统指标，他过去几周一直在从事的项目

00:01:53.880 --> 00:01:59.430
迈克尔，请让我在播音过程中变酷，现在让我

00:01:59.430 --> 00:02:05.009
知道什么时候可以看到，很酷，我想我很抱歉

00:02:05.009 --> 00:02:12.360
很棒，好吧，让我们开始内容吧，这有点好

00:02:12.360 --> 00:02:16.470
无论如何，所以我们构建的系统会使用

00:02:16.470 --> 00:02:22.709
gh存档，所以这是他们刚开始时遇到的问题，但基本上

00:02:22.709 --> 00:02:29.849
他们每小时都会放出一个文件，看起来像这样，有

00:02:29.849 --> 00:02:36.390
这是一个小时的公共数据，所以每个金属元素都是

00:02:36.390 --> 00:02:40.260
任何人在所有github公共资源中执行的每一项操作，因此

00:02:40.260 --> 00:02:46.739
任何推波助澜的人，看着回购者，对事物发表评论的人

00:02:46.739 --> 00:02:49.799
像这样，只有几件事情并没有真正得到解决

00:02:49.799 --> 00:02:53.310
你知道emoji表情竖起了什么东西，虽然它没有被抓住，但是那是一个

00:02:53.310 --> 00:02:56.459
大量的数据，所以如果您回溯大约两年或三年的时间，

00:02:56.459 --> 00:03:00.209
最终只能得到几TB的数据，但由于

00:03:00.209 --> 00:03:03.150
限速和一堆其他东西，这真的像唯一有效的

00:03:03.150 --> 00:03:08.970
种方法来查看整个github上的整个生态系统，所以我们真正想做的是

00:03:08.970 --> 00:03:13.440
就像能够以一种更明智的方式查询此信息，所以我们设计的是

00:03:13.440 --> 00:03:22.829
本质上是我们首先喜欢识别仓库的系统以及我们的方式

00:03:22.829 --> 00:03:27.450
这样做就像您知道我们可能要查看所有以下项的依赖关系图

00:03:27.450 --> 00:03:30.660
repos和ipfs，这样就给了我们全部依赖

00:03:30.660 --> 00:03:34.530
网络，然后我们想看一下所有

00:03:34.530 --> 00:03:39.660
github存档，或者我们可能使用bigquery或类似的东西，例如

00:03:39.660 --> 00:03:44.730
bigquery我们实际上可以看一下他们有一个日期的快照，我认为

00:03:44.730 --> 00:03:49.919
就像github上每个master分支中每个文件的月度一样，

00:03:49.919 --> 00:03:53.400
这样我们就可以说噢，就像Rica博士的样子

00:03:53.400 --> 00:03:56.940
里面有docker文件的所有仓库都是这样的

00:03:56.940 --> 00:04:00.660
您可以得到一个非常有用的信息，那就是bigquery相当昂贵

00:04:00.660 --> 00:04:04.709
虽然如此，我们确实需要限制那些查询，例如要查询的查询

00:04:04.709 --> 00:04:09.060
那些docker文件，大概一次要运行15美元，这样我们就可以确定

00:04:09.060 --> 00:04:14.900
一步进行回购，然后我们基本上希望获得一组过滤后的数据

00:04:14.900 --> 00:04:21.409
我将在这里解释该系统的工作原理，因此我们使用lambda和

00:04:21.409 --> 00:04:26.550
我们要做的是向lambda索要一个月的数据，所以

00:04:26.550 --> 00:04:32.280
该lambda函数称为筛选月，最后要做的是

00:04:32.280 --> 00:04:42.750
根据要过滤的月份和月份创建28到31个请求

00:04:42.750 --> 00:04:53.039
那么过滤日将向外部另一个Lambda发出24个请求

00:04:53.039 --> 00:05:00.750
该函数称为不对不起，它没有被过滤，它称为采摘，所以

00:05:00.750 --> 00:05:05.250
采摘是要做的，嗯，这是第一次要像我们一样检查

00:05:05.250 --> 00:05:08.789
如果不是，那么在s3中那个小时的那个github存档文件，我们将去获取

00:05:08.789 --> 00:05:15.120
然后将其放到s3中，然后使用称为s3 select的东西

00:05:15.120 --> 00:05:20.520
实际上，它允许您对CSV或JSON数据执行类似的续集查询，

00:05:20.520 --> 00:05:25.560
该数据甚至可以是gzip文件中的JSON行，因此它实际上可以完美地工作

00:05:25.560 --> 00:05:32.460
为了获得良好的档案，除了每隔几个月，有些人对

00:05:32.460 --> 00:05:37.440
github上有很多文件更新，甚至有关推送的元数据都是

00:05:37.440 --> 00:05:41.210
大于一个Meg，所以发生的是整个弹起功能都破裂了

00:05:41.210 --> 00:05:47.370
就像洋葱无法捕获的方式一样，所以当发生这种情况时，我们回头看了一下

00:05:47.370 --> 00:05:54.300
叫做他妈的后备的东西，这是S3实施的慢得多的版本

00:05:54.300 --> 00:05:58.500
和nodejs只是执行完全相同的操作，所以发生的是

00:05:58.500 --> 00:06:03.060
他们将要做的就是返回一个公正的

00:06:03.060 --> 00:06:07.740
到我们希望每个星期几都可以的对象的属性，所以

00:06:07.740 --> 00:06:12.330
回到这里最初的部分，当我们称过滤月时，我们也给出

00:06:12.330 --> 00:06:17.940
它就是我们所说的一种过滤器，它就像一个编码的

00:06:17.940 --> 00:06:23.250
seymour对象基本上存储在s3中，因此我们不必将其传递给

00:06:23.250 --> 00:06:26.430
lambda函数，因为它们实际上可能太大而无法传递

00:06:26.430 --> 00:06:30.779
在时间的lambda函数之间，因此Seymour对象不仅具有

00:06:30.779 --> 00:06:34.770
其中的这些flex值，以及想要过滤掉的所有存储库

00:06:34.770 --> 00:06:38.070
我猜这个插头组会滤掉所有

00:06:38.070 --> 00:06:41.920
抱歉，我是所有信息的唯一来源

00:06:41.920 --> 00:06:45.940
它关心的存储库，然后过滤一天将存储该存储库

00:06:45.940 --> 00:06:53.800
在s3中，所以您最终从这个过滤月请求中得到的是

00:06:53.800 --> 00:06:59.980
就像哦，您最终每小时只能得到一堆文件

00:06:59.980 --> 00:07:08.220
您最终过滤并插入的数据，然后我们执行另一项

00:07:08.220 --> 00:07:12.550
另一个名为scan cat的lambda函数，可以捕获所有这些文件

00:07:12.550 --> 00:07:16.840
一起将新值存储在s3中，这样我们就可以得到一年的价值

00:07:16.840 --> 00:07:21.100
我们基本上每个月一次只做一个月的数据

00:07:21.100 --> 00:07:27.700
介于700和1400之间的lambda函数，具体取决于缓存，而这些都是

00:07:27.700 --> 00:07:31.960
会并行运行，因此如果必须打回原位，则需要花费一些时间

00:07:31.960 --> 00:07:35.200
多一点，因为你是你离开了整个集会像

00:07:35.200 --> 00:07:39.640
最慢的请求，但是您会在不到10秒的时间内知道

00:07:39.640 --> 00:07:44.020
整个月的数据，然后我们一次做一个月

00:07:44.020 --> 00:07:48.490
我希望每次增加lamda速率限制时都拉一年，但是

00:07:48.490 --> 00:07:51.640
然后提高了Lambda的速率限制后，我们注意到

00:07:51.640 --> 00:07:54.940
也有三个速率限制，所以现在我们把s3吹灭了

00:07:54.940 --> 00:07:58.270
一旦我们开始在其中实际使用新的Landal，我们便会尝试限制

00:07:58.270 --> 00:08:01.000
弄清楚，希望我们最终能够在

00:08:01.000 --> 00:08:04.420
一段时间，然后我们可以在大约十秒钟内拉一年，但是就目前而言，

00:08:04.420 --> 00:08:07.690
知道我们可以在不到十分钟的时间内让您知道三年的数据价值

00:08:07.690 --> 00:08:13.420
所以这很好，但是关于这个系统的好处是，因为我们

00:08:13.420 --> 00:08:19.960
在这里取一个c-more对象，我们不受像多少个回购这样的限制

00:08:19.960 --> 00:08:23.530
我们可以查询的字面值可以过滤十万个

00:08:23.530 --> 00:08:26.470
存储库将需要更长的时间，因为每个存储库都将

00:08:26.470 --> 00:08:30.940
必须在s3上编码这个巨大的筛子或物体，但您知道我们可以做到

00:08:30.940 --> 00:08:34.780
大量的数据，这就是为什么我们不能使用某些数据的原因之一

00:08:34.780 --> 00:08:38.919
大型查询，大型查询等现成的东西也具有所有这些活动

00:08:38.919 --> 00:08:42.940
其中的数据，除了成本高昂之外，

00:08:42.940 --> 00:08:47.500
您可以这样做的单个查询的大小，因为只有一个

00:08:47.500 --> 00:08:50.320
查询我们不喜欢果酱，您知道那里有十万个回购，所以我们不得不

00:08:50.320 --> 00:08:54.310
切碎他们，然后它会是疯狂的昂贵，所以是的

00:08:54.310 --> 00:09:00.490
基本上这就是我们可以做到的方式，这使我们能够提取非常精简的数据集

00:09:00.490 --> 00:09:02.950
只是我们关心的值，只是我们关心的存储库

00:09:02.950 --> 00:09:09.640
系统，所以现在有了我们这个系统，最终发生的事情是

00:09:09.640 --> 00:09:13.960
只要我们基本上可以将生态系统变成存储库，我们就可以

00:09:13.960 --> 00:09:17.560
筛选出这些数据集，然后实际上只是像

00:09:17.560 --> 00:09:21.310
处理指标，这就是我们目前所处的阶段

00:09:21.310 --> 00:09:24.490
我们正在尝试找出可以从这项权利中获得的有用数据，以便您

00:09:24.490 --> 00:09:30.160
可以做类似我们可以得到参与的人一样的独特事物

00:09:30.160 --> 00:09:33.880
不同类型的活动或所有活动，所以我们可以说谁是所有

00:09:33.880 --> 00:09:37.600
致力于这个生态系统的人

00:09:37.600 --> 00:09:41.410
无论如何，所以即使在您那里，您也知道类似的问题评论之类的内容

00:09:41.410 --> 00:09:45.100
您可以假设他们就像系统的用户一样，您也可以看看

00:09:45.100 --> 00:09:49.720
你知道整个活动的水平，就像贾斯汀在下降

00:09:49.720 --> 00:09:54.279
还是您仍然知道整体活动有所增加，然后

00:09:54.279 --> 00:09:57.520
最重要的是，您可以获取所有这些数据，然后可以开始查看

00:09:57.520 --> 00:10:01.750
就像这个生态系统的增长率是多少

00:10:01.750 --> 00:10:06.910
您想看看在不同时间段增长的唯一身份用户

00:10:06.910 --> 00:10:10.630
是的，这就是我们现在正在对系统进行的操作的主要原因

00:10:10.630 --> 00:10:14.440
我想向人们展示该系统及其工作原理，因为它是一个

00:10:14.440 --> 00:10:18.220
与您记录指标的传统指标系统略有不同

00:10:18.220 --> 00:10:21.580
在某个数据库中，然后您可以对其进行查询，我们实际上需要您

00:10:21.580 --> 00:10:26.530
知道去从github过滤这个巨大的数据集，然后变得有趣

00:10:26.530 --> 00:10:30.670
从那里评估指标，但有了它，我们不仅可以查看我们的生态系统

00:10:30.670 --> 00:10:34.570
正确，对于ipfs，让p2p和所有其他系统，但是我们可以看一下

00:10:34.570 --> 00:10:38.050
对我们可能感兴趣的生态系统感兴趣的生态系统

00:10:38.050 --> 00:10:41.560
软件包经理的工作，我们可以说很好，码头工人的增长是多少

00:10:41.560 --> 00:10:46.240
文件与打包JSON文件进行比较，并了解有多少人参与其中，以及

00:10:46.240 --> 00:10:48.700
这里有趣的事情之一是，当您看到不同的

00:10:48.700 --> 00:10:53.320
您知道软件包数量和软件包管理器数量的生态系统

00:10:53.320 --> 00:10:57.130
增长，或者您知道docker文件的数量可能会以不同的方式增长

00:10:57.130 --> 00:11:01.480
储存库，但可能会有很大的不同，而且使用者的数量

00:11:01.480 --> 00:11:05.560
四，五年前我进行分析时使用的那些生态系统

00:11:05.560 --> 00:11:10.149
更糟糕的工具只是从前端分离出后端JavaScript

00:11:10.149 --> 00:11:13.810
 JavaScript在数量上有明显的不同

00:11:13.810 --> 00:11:18.279
人们从事那些前端项目，因此您可以

00:11:18.279 --> 00:11:21.700
关联到有更多的人在使用那些人，实际上有更多的用户

00:11:21.700 --> 00:11:26.500
这些项目而不是后端项目，所以这给了我们真正的

00:11:26.500 --> 00:11:30.610
不同开源生态系统之间有趣的竞争分析

00:11:30.610 --> 00:11:35.500
也是的，我想在这一点上我可以提出问题

00:11:35.500 --> 00:11:47.440
这不像是一场巨大的演讲，是的，让我们继续提问可能会向我展示

00:11:47.440 --> 00:11:53.320
我自己很好，非常感谢你，对于那些有疑问的人，如果你只是把

00:11:53.320 --> 00:12:05.890
它在聊天框中会很好，所以我有任何疑问吗

00:12:05.890 --> 00:12:12.670
问题似乎就在您在哪里，如果那只是

00:12:12.670 --> 00:12:17.649
它足够干净，您可以分析它是否对您感兴趣

00:12:17.649 --> 00:12:28.149
在ipfs上做出贡献的人和活动的条件

00:12:28.149 --> 00:12:33.190
太早了，无法像真正的外卖一样走开，我们仍然有点

00:12:33.190 --> 00:12:37.240
像现在这样完善我们如何做回购识别码

00:12:37.240 --> 00:12:44.140
对于回购ID，我正在使用库的io数据，并且有一个很大的

00:12:44.140 --> 00:12:48.910
像github依赖之间的差异怎么办，如果您进入

00:12:48.910 --> 00:12:51.640
github repo那里有一个“ dependss”选项卡，您可以看到所有存储库

00:12:51.640 --> 00:12:57.190
我在您的存储库中，那里的存储库比库中的存储库多得多

00:12:57.190 --> 00:13:01.839
io数据可能是因为库IO的运行非常复杂

00:13:01.839 --> 00:13:06.250
他们尝试查看软件包中回购数据的操作

00:13:06.250 --> 00:13:10.390
JSON，然后通过依赖关系图将其关联回去，但不是所有人

00:13:10.390 --> 00:13:15.699
拥有最新的元数据，而像github一样，您知道所有

00:13:15.699 --> 00:13:19.420
重新定位自己，以便他们知道package.json是否依赖于该软件包

00:13:19.420 --> 00:13:23.020
命名一个他们甚至可以拉的地方，您知道依赖的存储库

00:13:23.020 --> 00:13:26.320
它没有以任何方式发布，因此非常有用

00:13:26.320 --> 00:13:31.390
嗯，是的，但是来自github的数据的问题是

00:13:31.390 --> 00:13:35.770
没有API，因此请戳他们以尝试让他们将这些数据提供给我

00:13:35.770 --> 00:13:38.770
没有我的一些有用的方式就像是通过

00:13:38.770 --> 00:13:44.560
网站和bi yeah，所以我看过的东西就像看的数据一样

00:13:44.560 --> 00:13:50.170
我们生态系统中的一个有趣的事情是，到目前为止，这些项目

00:13:50.170 --> 00:13:54.010
在与我们相似的空间中，我的曲线非常相似，它们是

00:13:54.010 --> 00:13:57.820
成长，因此您似乎知道我们所处的空间

00:13:57.820 --> 00:14:01.510
集中化空间正在以特定的速度增长，我们正在

00:14:01.510 --> 00:14:06.490
所有的东西都很好地生长，这是一种有趣的外卖方式，但是

00:14:06.490 --> 00:14:12.730
我有点在等待获取更多数据并完善我们的回购标识

00:14:12.730 --> 00:14:17.710
我对此也做了很多其他的判断，就像我真的很想看看

00:14:17.710 --> 00:14:22.510
更成熟的生态系统，并在某种程度上看到了其增长的特殊之处

00:14:22.510 --> 00:14:24.910
尖峰以及不同曲线的走向，看看是否可以找到

00:14:24.910 --> 00:14:28.150
他们之间的相关性，然后我们可以看一下我们的成长并说好

00:14:28.150 --> 00:14:31.690
我们处于哪个成熟阶段？

00:14:31.690 --> 00:14:35.830
的原因是，在贝尔维尔，我们还没有什么好东西

00:14:35.830 --> 00:14:39.760
从字面上看就像是让系统正常工作，然后每次

00:14:39.760 --> 00:14:43.180
然后我们喜欢做一些改进以使其有所改进

00:14:43.180 --> 00:14:46.690
更快，然后炸毁了我们不知道的新速率限制

00:14:46.690 --> 00:14:50.950
某个地方，然后我们将其搜寻下来，然后添加新的缓存层，

00:14:50.950 --> 00:14:55.180
炸毁了您的速率限制，因为事情更快，所以很多

00:14:55.180 --> 00:14:58.030
就像您查看存储库一样，

00:14:58.030 --> 00:15:02.260
现在获得相对稳定的代码和方法

00:15:02.260 --> 00:15:07.570
本质上就像在过滤月的阶段，实际上是一个费率

00:15:07.570 --> 00:15:11.290
限制或试图估计SLAM的潜在数量

00:15:11.290 --> 00:15:18.640
它会调用的函数，您基本上可以更改此问题

00:15:18.640 --> 00:15:28.000
与手机Jonny Quest非常相似，到目前为止，我有很多见识，是的，我认为

00:15:28.000 --> 00:15:33.010
我有点遮掩，嗯，遮遮掩掩的范围不止那里

00:15:33.010 --> 00:15:38.649
到目前为止，我的人洞察力是LEM de就像超级强大，可以做到

00:15:38.649 --> 00:15:42.009
这种东西真的非常快，例如，如果您在本地运行

00:15:42.009 --> 00:15:48.129
自己的机器可能需要一个月的时间，但是您可以更快地完成

00:15:48.129 --> 00:15:53.829
真的很讨厌没有证件，就像没有证件一样

00:15:53.829 --> 00:16:00.970
跟踪所有内容，而且这在lamda世界中并不常见

00:16:00.970 --> 00:16:05.499
就像从零到成千上万个函数突然又回落到零一样

00:16:05.499 --> 00:16:11.679
像平常一样，接下来我们会遇到很多类似的事情

00:16:11.679 --> 00:16:16.869
ollie的问题到目前为止，您是否有任何令人兴奋的头条统计数据

00:16:16.869 --> 00:16:23.709
任何惊喜，我想那还没有，因为您仍然

00:16:23.709 --> 00:16:27.879
早期阶段，我正在分析数据，是的，所以现在我正在尝试

00:16:27.879 --> 00:16:31.209
只是将数据提供给项目，然后让项目决定

00:16:31.209 --> 00:16:34.059
他们想要从那个um中提取什么样的最重要的数字

00:16:34.059 --> 00:16:38.619
一般而言，我只会对顶线数字保持谨慎

00:16:38.619 --> 00:16:42.999
这些估算值是正确的，就像不是每个人，并非我们所有的用户都参与其中

00:16:42.999 --> 00:16:48.910
一个公共存储库并非我们所有用户的公共存储库，您也知道我们

00:16:48.910 --> 00:16:53.980
就像现在没有一个很好的方法来观察NGO生态系统一样

00:16:53.980 --> 00:16:56.889
有包裹分钟的情况，这很糟糕

00:16:56.889 --> 00:17:02.410
就像我们为JavaScript项目所做的依赖网络一样

00:17:02.410 --> 00:17:06.100
只是在那儿不行，所以我们必须找出类似

00:17:06.100 --> 00:17:10.750
bigquery分析github中的每个go文件并尝试确定它们是否

00:17:10.750 --> 00:17:14.799
在go文件中使用IP FS来标识存储库，所以我们有点

00:17:14.799 --> 00:17:19.600
我们在那里丢失了一些数据，所以我们进入了现在所在的州

00:17:19.600 --> 00:17:22.059
只是尝试在我不想拉出顶线的地方进行优化

00:17:22.059 --> 00:17:25.329
数字，我认为我们现在要拉的最重要的只是增长

00:17:25.329 --> 00:17:28.929
正确的增长率就像您知道我们是否不抽样的增长率

00:17:28.929 --> 00:17:34.120
足够，或者如果我们将其与另一个进行比较，我们可能会过度采样

00:17:34.120 --> 00:17:40.000
生态系统应该保留相同的偏见，因此我们应该能够进行比较

00:17:40.000 --> 00:17:44.200
至少即使我们知道您知道这些数字

00:17:44.200 --> 00:17:49.150
不会一直给我们确切的人数，或者抱歉

00:17:49.150 --> 00:17:52.810
我认为还有非常完全准确的人数

00:17:52.810 --> 00:17:57.760
我们需要考虑的是，您越走越远的地方

00:17:57.760 --> 00:18:01.660
依赖包网络，您在被动使用中会更多

00:18:01.660 --> 00:18:05.530
而不是像人们没有主动说嘿安装这样的主动使用方式

00:18:05.530 --> 00:18:09.520
ipfs对于我来说，他们安装了所有ID或已安装的东西

00:18:09.520 --> 00:18:14.050
我想把客户纳入其中，所以您可能还想将其分开

00:18:14.050 --> 00:18:17.110
可能不想说就像您只知道一个层次的深度或两个层次的深度一样

00:18:17.110 --> 00:18:21.910
深度，深度图是我们想要去的，其余的

00:18:21.910 --> 00:18:23.520
我们将变灰

00:18:23.520 --> 00:18:27.310
是的，现在我们正在寻找查看这些数据的最佳方法，

00:18:27.310 --> 00:18:31.420
切成薄片，是的，我不想提出类似的投诉

00:18:31.420 --> 00:18:38.770
现在的人数很好非常感谢Rob的下一个问题

00:18:38.770 --> 00:18:44.320
Brackett有什么我们打算从这一切中使用的特定用途

00:18:44.320 --> 00:18:52.210
信息，所以我现在正在尝试将一些数据输入到我们正在处理的过程中

00:18:52.210 --> 00:18:57.130
围绕包裹管理器做事，我真的很想找到衡量这些包裹的好方法

00:18:57.130 --> 00:19:01.690
生态系统，以便我们可以在决策过程中提供我们所需要的数据

00:19:01.690 --> 00:19:05.110
也只是打印了一种快速的指标，而我们只是试图获得一个

00:19:05.110 --> 00:19:11.140
几个不同项目中的大量数据，这给了我们一些基本信息

00:19:11.140 --> 00:19:19.090
在组织中Lupita Pei PFS和IP LD的软件包上，所以我们

00:19:19.090 --> 00:19:21.940
可以看到现在的进一步增长率是多少

00:19:21.940 --> 00:19:28.480
只是在我们自己的项目上活动，但是是的，我们整个

00:19:28.480 --> 00:19:31.570
在整个组织中有点像KPI情况下的指标

00:19:31.570 --> 00:19:36.400
现在就像记录数据一样，弄清楚我们如何获取数据，然后我们

00:19:36.400 --> 00:19:40.210
一旦有了大量数据，那么我们就可以开始讨论最佳方法

00:19:40.210 --> 00:19:45.400
使用它并对其进行分析，所以是的，这就像本演示文稿中的很多内容一样

00:19:45.400 --> 00:19:48.520
这样做是为了打开可能的问题

00:19:48.520 --> 00:19:53.050
询问数据，因为现在我们可以捕获整个生态系统数据，

00:19:53.050 --> 00:19:56.620
请把这些问题反馈到流程中，我们

00:19:56.620 --> 00:20:00.970
可以改进工具并再次运行这些回归，并开始提供更多信息

00:20:00.970 --> 00:20:08.710
并将更多指标和数据纳入整个流程，下一条评论是

00:20:08.710 --> 00:20:13.720
吉姆·皮茨（Jim Pitts）说，我很乐意看到一些同类研究分析，看看有多少人

00:20:13.720 --> 00:20:17.760
正在做出贡献，然后将其证明

00:20:20.250 --> 00:20:26.070
[音乐]搅动搅动抱歉证明了

00:20:26.070 --> 00:20:35.230
viii您是我，而我的引擎却转身对不起，我想要的是

00:20:35.230 --> 00:20:52.150
对这个问题感到困惑，抱歉，这只是评论哦，是的，分析

00:20:52.150 --> 00:20:59.230
博士的内容文件um，所以我们将为此使用bigquery，以便bigquery可以看起来

00:20:59.230 --> 00:21:03.760
在所有医生文件的内容上以及在github上，然后从

00:21:03.760 --> 00:21:07.270
我们将获得一组回购，因此，如果我们想进行某种匹配

00:21:07.270 --> 00:21:13.360
然后在docker文件中，是的，我们会告诉我们，就像您知道是否

00:21:13.360 --> 00:21:16.270
doctor文件中包含此内容，请告诉我，或告诉我回购名称，或

00:21:16.270 --> 00:21:20.080
告诉我文件或其他内容，然后我们可以对整个文件进行过滤器分析

00:21:20.080 --> 00:21:25.090
所有这些存储库中的存储库，但是系统本身没有

00:21:25.090 --> 00:21:31.600
bigquery中所有存储库的内容都很好，是的

00:21:31.600 --> 00:21:37.750
我们替换掉那将是巨大的，我的意思是，这不是一个巨大的胜利

00:21:37.750 --> 00:21:41.500
对我们来说，因为我们需要对实际文件执行的查询类型

00:21:41.500 --> 00:21:47.920
现在的内容非常少，就像您知道的，我们只需要看看

00:21:47.920 --> 00:21:53.620
通常情况下有些东西匹配，所以我们可以知道，您知道付十五美元吗？

00:21:53.620 --> 00:21:56.920
或任何查询获取该数据，然后具有存储库集和

00:21:56.920 --> 00:22:00.700
然后像这样，查看所有元数据将是更具成本效益的系统

00:22:00.700 --> 00:22:08.380
对那些存储库的分析，是的，希望这些都很棒

00:22:08.380 --> 00:22:11.850
问题还有其他问题吗

00:22:13.919 --> 00:22:20.669
如果我们没有任何问题，这对我来说是无处不在的，那么我们就可以早点结束

00:22:20.669 --> 00:22:31.649
酷啊，不用了，谢谢，我是安德鲁，可以用来将数据打包在一起

00:22:31.679 --> 00:22:40.749
你的意思是说安德鲁想在那里再谈一会儿

00:22:40.749 --> 00:22:48.779
很抱歉，我只需要将麦克风插入不，所以我想

00:22:48.779 --> 00:22:57.009
而不是像文件中具有匹配项或某些内容的仓库一样

00:22:57.009 --> 00:23:07.179
有没有所有人都说使用这些的存储库集群

00:23:07.179 --> 00:23:14.200
五个包裹，或者像其他集体包裹一样经过什么先生

00:23:14.200 --> 00:23:21.840
通常会一起用于

00:23:21.840 --> 00:23:30.340
相似或共享的代码位，例如ipfs库始终

00:23:30.340 --> 00:23:36.609
这些东西可能需要一起点亮p2p相关

00:23:36.609 --> 00:23:45.690
例如东西，但我们也可以突出显示类似类型的

00:23:45.690 --> 00:23:51.869
人们使用ipfs来了解位置的依赖关系的类型

00:23:51.869 --> 00:23:56.559
可能几乎就像亚马逊推荐的东西一样

00:23:56.559 --> 00:24:02.909
与一组给定的软件包有关，我真的对ipfs最感兴趣

00:24:02.909 --> 00:24:09.909
包，特别是，是的，您不能为此使用它，但是我认为

00:24:09.909 --> 00:24:14.679
您可以正确使用github API，好吧，首先您必须抓取

00:24:14.679 --> 00:24:19.479
他们没有API的愚蠢依赖项，但是当谁发现时

00:24:19.479 --> 00:24:25.750
所有实际上依赖于它的repos和github他们

00:24:25.750 --> 00:24:28.510
那你就只看他们儿子的包裹，然后开始

00:24:28.510 --> 00:24:32.830
基本上记录所有程序包，并查看哪些是顶级程序包

00:24:32.830 --> 00:24:36.850
是必需的，然后您可以使用该系统执行

00:24:36.850 --> 00:24:41.050
分析这些存储库，并找到最活跃的人员

00:24:41.050 --> 00:24:45.130
因此，您可以开始喜欢将IP FS包含在系统中，

00:24:45.130 --> 00:24:48.940
它与它一起使用，然后进行生态系统分析，从而使人们

00:24:48.940 --> 00:24:54.220
他们两个人的活动，看看它们之间有什么相关性

00:24:54.220 --> 00:24:58.290
那会很有趣哦

00:25:02.160 --> 00:25:11.350
好吧，还有其他问题吗？谢谢迈克尔。

00:25:11.350 --> 00:25:19.780
演讲，下周的下周一，我会见到每个人。

00:25:19.780 --> 00:25:26.640
 ipfs回忆起，祝您度过愉快的一周，再见

