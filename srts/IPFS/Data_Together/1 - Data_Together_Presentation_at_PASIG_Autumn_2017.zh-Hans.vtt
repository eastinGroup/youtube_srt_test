WEBVTT
Kind: captions
Language: zh-Hans

00:00:00.000 --> 00:00:04.350
嗨，我是Matt Zumwalt，这是我在演讲中的录音

00:00:04.350 --> 00:00:11.130
2017年秋天在牛津大学拜访这是一次数字会议

00:00:11.130 --> 00:00:18.359
我在全球工作的图书馆和档案馆的保存专家

00:00:18.359 --> 00:00:23.550
协议实验室，它是针对

00:00:23.550 --> 00:00:29.670
网络我们的主要项目是ipfs行星际文件系统和文件

00:00:29.670 --> 00:00:34.680
您可能最近在新闻中听说过的声明，我们也有一个数字

00:00:34.680 --> 00:00:41.640
专注于在Web上构建模式的底层开源项目

00:00:41.640 --> 00:00:51.059
使得我们使用的协议能够适应未来的发展，所以当我说我们专注于

00:00:51.059 --> 00:00:56.550
分散网络或Reedy集中网络是一种有用的方法

00:00:56.550 --> 00:01:02.520
通过参考早期论文中的图表来解释这一点

00:01:02.520 --> 00:01:08.369
互联网的发展，因此该论文于1962年发表在

00:01:08.369 --> 00:01:13.500
左图显示了一个客户端-服务器体系结构，如果您想像每个

00:01:13.500 --> 00:01:17.939
这些图中每个点中的点都是网络上的机器还是节点

00:01:17.939 --> 00:01:24.119
在您的客户-服务器结构中，您有一台服务器可以为许多客户提供服务，

00:01:24.119 --> 00:01:27.540
这些客户端无法彼此连接，他们只能连接

00:01:27.540 --> 00:01:32.520
到中间图（本文称为分散式）中的服务器

00:01:32.520 --> 00:01:36.630
您有一个联合的体系结构，其中某些计算机能够与之连接

00:01:36.630 --> 00:01:41.880
彼此，但是其他客户端节点只能连接到那些

00:01:41.880 --> 00:01:46.920
超级节点，它们无法直接相互连接，并且

00:01:46.920 --> 00:01:50.880
然后在右边，您拥有一个点对点架构，其中任何节点

00:01:50.880 --> 00:01:55.500
能够与任何其他节点连接，但我也能够依靠其他

00:01:55.500 --> 00:01:59.610
节点在其他节点之间传递信息时作为中继

00:01:59.610 --> 00:02:01.909
在网络上

00:02:03.600 --> 00:02:10.560
所以我进入去中心化工作的方式是

00:02:10.560 --> 00:02:14.459
多年帮助图书馆和档案馆建立策展系统

00:02:14.459 --> 00:02:20.220
他们的数字收藏，尤其是倾向于保存，但

00:02:20.220 --> 00:02:24.300
当我们看到网络开发人员在我们周围时，很明显有

00:02:24.300 --> 00:02:30.810
我想将其视为数字囚禁的一种形式，

00:02:30.810 --> 00:02:36.810
我们创建的数据正被诸如动物园之类的东西捕获

00:02:36.810 --> 00:02:42.090
一个笼子里，不允许数据在野外壮成长，也不在

00:02:42.090 --> 00:02:46.020
它的创建者的控制权被迫存在于某些地方

00:02:46.020 --> 00:02:52.830
由其他方控制并作为我的工作的预配置系统

00:02:52.830 --> 00:02:58.430
在帮助图书馆和档案馆建立自己的系统方面取得了进展

00:02:58.430 --> 00:03:02.220
确信我们所创建的系统仍然是我们仍然

00:03:02.220 --> 00:03:06.480
尽管我们只是出于最好的意图参加了相同的系统

00:03:06.480 --> 00:03:10.260
建立另一种形式的笼子而不是帮助那些顾客

00:03:10.260 --> 00:03:17.120
图书馆和档案馆以其野外存在的数据蓬勃发展，所以我

00:03:17.120 --> 00:03:28.680
变得非常坚信，解决方案是立即重建网络

00:03:28.680 --> 00:03:34.410
让我们看一个回应2016年大选的例子

00:03:34.410 --> 00:03:39.510
人们开始担心新的联邦政府将开始

00:03:39.510 --> 00:03:43.160
通过关闭服务器或减少服务器来减少气候数据的可用性

00:03:43.160 --> 00:03:48.120
以其他方式阻碍了可用性，因此出现了膨胀

00:03:48.120 --> 00:03:55.890
人们试图将数据从计算机移动到其他更安全的位置的努力

00:03:55.890 --> 00:03:59.940
保存观点，考虑这意味着什么很重要

00:03:59.940 --> 00:04:03.360
这是成千上万的人花费数天或数月的生命

00:04:03.360 --> 00:04:10.290
现在尝试保存其他人的数据

00:04:10.290 --> 00:04:15.810
有一些意想不到的后果

00:04:15.810 --> 00:04:20.850
现在要记住的是，这些人正在尝试帮助

00:04:20.850 --> 00:04:25.290
这些联邦机构是关心EPA的人，他们关心

00:04:25.290 --> 00:04:30.389
关于EPA产生的数据，但是当他们复制数据时，

00:04:30.389 --> 00:04:35.580
数据变成了与原始数据竞争的东西，所以这些

00:04:35.580 --> 00:04:40.620
数据已移至的新位置正在与

00:04:40.620 --> 00:04:46.260
我们正在与EPA竞争而不是加强EPA的原始资源

00:04:46.260 --> 00:04:49.500
是因为网络本身的结构是强制这种类型的

00:04:49.500 --> 00:04:53.700
竞争我们需要的是Web的另一种结构，它很容易

00:04:53.700 --> 00:04:57.990
复制数据，一旦您复制了数据，就很容易验证

00:04:57.990 --> 00:05:02.550
在网络上不同位置的两个副本是相同的，

00:05:02.550 --> 00:05:08.280
通过该网络复制数据可提高可用性

00:05:08.280 --> 00:05:12.330
而不是创造一个竞争局面，即拥有更多的副本

00:05:12.330 --> 00:05:17.490
网络上的数据只会增加节点可以遵循的路径数量

00:05:17.490 --> 00:05:22.620
以便通过切换到此替代方案来检索所需的数据

00:05:22.620 --> 00:05:27.120
网络上的模式会带来一种新的对话方式，而不是

00:05:27.120 --> 00:05:31.830
一场充满信心的比赛，以确定我们应该依靠的位置

00:05:31.830 --> 00:05:35.910
取而代之的是，它变成了有关哪些数据有风险的对话

00:05:35.910 --> 00:05:40.350
他们面临什么风险？为什么这些数据有价值？他们是谁？

00:05:40.350 --> 00:05:47.310
对谁有价值，谁应该持有它的副本

00:05:47.310 --> 00:05:50.850
潜在的方式是将访问发现和保存变成

00:05:50.850 --> 00:05:55.470
参与性活动，它们成为关心人们之间的对话

00:05:55.470 --> 00:05:58.950
关于数据以及代表的机构和社区组织

00:05:58.950 --> 00:06:04.200
他们或汇总这些社区的资源，因此，如果我们将其表示为

00:06:04.200 --> 00:06:07.200
简单的原则是信息应该是

00:06:07.200 --> 00:06:10.680
依赖它的人以及那个社区和机构所拥有的

00:06:10.680 --> 00:06:15.120
应该汇总信息和资源以支持访问发现

00:06:15.120 --> 00:06:21.210
并从我们的图书馆和档案馆的角度进行保存

00:06:21.210 --> 00:06:26.130
这些想法不应该是革命性的，它们既简单又

00:06:26.130 --> 00:06:29.380
简单明了，那是因为图书馆和档案馆

00:06:29.380 --> 00:06:34.180
被创建为共享信息资源的一种手段，但是

00:06:34.180 --> 00:06:38.770
让我们看一下当前网络结构如何阻碍

00:06:38.770 --> 00:06:43.480
之所以能够实现这一目标，是因为当前的当前网络结构使用了

00:06:43.480 --> 00:06:47.920
位置寻址的方法我们通过内容的位置来识别内容，而不是

00:06:47.920 --> 00:06:51.940
而不是内容寻址，您可以在其中标识和标识信息

00:06:51.940 --> 00:06:57.100
内容，因此举一个简单的例子，如果您考虑一下我们如何识别一本书

00:06:57.100 --> 00:07:01.450
我向您推荐一本书，根据您应该阅读本书的内容，我向您推荐

00:07:01.450 --> 00:07:05.470
这个作者的这个标题，我可能会告诉你它什么时候出版或什么

00:07:05.470 --> 00:07:10.150
出版商是，您可以去找到与该书匹配的任何副本

00:07:10.150 --> 00:07:13.960
对其内容进行描述，并在阅读本书时确信自己是

00:07:13.960 --> 00:07:18.460
阅读本书，我建议这与我们的方式有很大不同

00:07:18.460 --> 00:07:23.770
识别网络上的内容，因为当我使用HTTP链接时在网络上

00:07:23.770 --> 00:07:28.870
指向一个位置，然后当您使用该位置检索该位置时

00:07:28.870 --> 00:07:32.890
内容，如果您下载它的副本，则说明您正在通过

00:07:32.890 --> 00:07:36.340
网络的观点是根本不同的，因为

00:07:36.340 --> 00:07:40.750
如果我们开始使用指向其他位置的链接，那么它现在位于其他位置

00:07:40.750 --> 00:07:45.880
内容的每个副本都在不同的位置

00:07:45.880 --> 00:07:50.020
具有自己标识符的位置，该标识符具有自己依赖谁的个人资料

00:07:50.020 --> 00:07:54.490
并指向它，所以这就是您创建这种情况的地方，甚至

00:07:54.490 --> 00:07:58.720
如果您正在复制内容以增强可用性

00:07:58.720 --> 00:08:03.790
您实际上正在破坏原始副本，因为您正在与原始版本竞争

00:08:03.790 --> 00:08:11.290
是现在的位置替代方法是使用寻址的内容

00:08:11.290 --> 00:08:16.090
使用数字信息的方法，因此内容寻址的主要好处是

00:08:16.090 --> 00:08:19.810
如果网络上的任何人都有内容的副本，您将能够找到它

00:08:19.810 --> 00:08:24.790
并检索它，这里的关键思想是位置无关紧要

00:08:24.790 --> 00:08:29.800
重要的是，您能够获得所需的内容并成为

00:08:29.800 --> 00:08:36.010
有信心您正在检索所需的内容以及我们的方式

00:08:36.010 --> 00:08:40.089
通过现在使用加密散列进行数字保存来实现此目的

00:08:40.089 --> 00:08:43.779
社区，这应该是一个熟悉的概念，因为我们将这种模式用于

00:08:43.779 --> 00:08:49.029
固定性检查，您可以在其中通过加密将任何内容放入其中

00:08:49.029 --> 00:08:53.680
哈希算法，该算法会生成一个唯一的字母字符串，

00:08:53.680 --> 00:08:59.170
如果您通过完全相同的内容表示内容的数字

00:08:59.170 --> 00:09:03.160
该算法将始终获得相同的哈希值，因此您将获得

00:09:03.160 --> 00:09:08.410
结果是相同的字母和数字字符串，但是如果您将内容

00:09:08.410 --> 00:09:13.000
如果内容已更改，则即使在内容中甚至一点也没有改变

00:09:13.000 --> 00:09:17.560
您将得到一个不同的哈希，所以这意味着这些哈希是

00:09:17.560 --> 00:09:24.399
通用唯一标识符，用于将内容准确地包含在内容中

00:09:24.399 --> 00:09:28.930
解决方法，我们使用这些散列作为内容的标识符，

00:09:28.930 --> 00:09:33.190
这样做的好处是该好处，或者网络上的任何人都有该好处的副本

00:09:33.190 --> 00:09:37.360
内容，您将能够使用该哈希请求它，并且您将能够

00:09:37.360 --> 00:09:40.750
从他们那里检索到它之后，您便可以进行验证

00:09:40.750 --> 00:09:44.860
针对您使用的哈希值，可以针对该哈希值标识符对其进行验证

00:09:44.860 --> 00:09:50.440
并知道您已获取了所请求的内容，让我们看一下

00:09:50.440 --> 00:09:55.660
这会影响诸如数据访问之类的模式，如果我拥有已经拥有的内容

00:09:55.660 --> 00:10:00.279
在任何时候都使用内容寻址方法与同行共享

00:10:00.279 --> 00:10:04.120
我可以与该库共享该标识符，并且该库可以加入

00:10:04.120 --> 00:10:09.730
该内容，我永远不必上传该内容，我所要做的就是

00:10:09.730 --> 00:10:12.639
将标识符传递给图书馆，他们就可以从

00:10:12.639 --> 00:10:17.019
自己建立网络，但您可以以更强大的方式来完成此操作，因为我可能会提交

00:10:17.019 --> 00:10:22.750
有关我的内容的元数据，或者我可能会提交信息元数据，例如

00:10:22.750 --> 00:10:27.250
版本历史记录，因此您可以拥有一系列的数据集版本，

00:10:27.250 --> 00:10:30.819
认为对于图书馆收藏我的藏书很重要

00:10:30.819 --> 00:10:34.779
要做的是提交内容的版本历史记录的哈希，所以我要提交

00:10:34.779 --> 00:10:40.000
元数据的哈希和库可以提取整个语料库

00:10:40.000 --> 00:10:47.680
信息，包括他们认为合适的元数据，是该模式的基础

00:10:47.680 --> 00:10:51.279
使之强大的原因是您使用的是散列链接的数据结构

00:10:51.279 --> 00:10:54.920
所以这是一种我们已经看到影响的模式

00:10:54.920 --> 00:10:59.329
直通我们行业的各个领域或技术行业的各个领域

00:10:59.329 --> 00:11:04.100
诸如获得Apache Spark或比特币和BitTorrent之类的技术

00:11:04.100 --> 00:11:09.769
所有这些基于它们的技术都在使用哈希模式

00:11:09.769 --> 00:11:13.970
链接到数据结构，这有什么好处，为什么我们要使用哈希

00:11:13.970 --> 00:11:18.679
链接数据结构，所以一个好处是我们可以将内容与其分离

00:11:18.679 --> 00:11:23.209
我们已经讨论过的位置允许存在任何内容

00:11:23.209 --> 00:11:28.389
在很多地方，并通过许多人的手而不会失去完整性

00:11:28.389 --> 00:11:33.109
底层就是这种密码完整性检查的概念，您可以

00:11:33.109 --> 00:11:38.299
使用链接值本身，您可以使用该哈希值来验证内容

00:11:38.299 --> 00:11:43.790
您所拥有的，因此，这是用于确保以下内容的完整性的强大工具

00:11:43.790 --> 00:11:50.379
随着时间的流逝整个数据系统以及它们通过网络传输的术语

00:11:50.379 --> 00:11:54.859
现在最基本的东西就是建立哈希链接数据结构

00:11:54.859 --> 00:11:59.089
强大的功能就是您正在创建不可变的数据结构，因此

00:11:59.089 --> 00:12:02.959
不变数据结构的这一概念在

00:12:02.959 --> 00:12:07.220
自计算机语言或计算机技术问世以来，它就已经存在了。

00:12:07.220 --> 00:12:11.899
编程语言，这里的主要思想是您可以创建数据

00:12:11.899 --> 00:12:15.980
不会变异的结构以及创建新版本时的结构

00:12:15.980 --> 00:12:25.100
数据中，您具有该新版本的新标识符，因此将其组合在一起

00:12:25.100 --> 00:12:29.809
让我们看看当您运行一个ipfs节点之一时ipfs是如何做到的。

00:12:29.809 --> 00:12:32.929
您可以从命令行添加内容的方式很多

00:12:32.929 --> 00:12:36.709
您可以用来向ipfs节点添加内容的不同api，但这

00:12:36.709 --> 00:12:42.139
给我们一个简单的例子，所以如果我有一个文件或整个文件集

00:12:42.139 --> 00:12:46.970
我的系统或系统上的数据集，我可以告诉ipfs添加

00:12:46.970 --> 00:12:52.639
内容存储到其存储库中，并且ipfs将返回加密哈希

00:12:52.639 --> 00:12:58.100
标识内容，然后我可以使用该哈希值通过以下方式请求内容

00:12:58.100 --> 00:13:02.419
网络上任何地方的任何ipfs节点，该节点将能够使用该ipfs节点。

00:13:02.419 --> 00:13:05.490
哈希以检索内容，对其进行验证并返回

00:13:05.490 --> 00:13:12.510
对我而言，我的PFS节点也与HTTP Web向后兼容

00:13:12.510 --> 00:13:17.430
今天我们知道的网络，您可以在其中使用这些哈希值询问任何IP FS节点

00:13:17.430 --> 00:13:24.570
为您检索内容，这使诸如Web浏览器之类的工具能够

00:13:24.570 --> 00:13:30.020
使用HTTP检索实际上存储在对等Web上的内容

00:13:30.020 --> 00:13:35.279
现在来看一个具体的例子，这里的文字要小一些，但这是一个

00:13:35.279 --> 00:13:41.220
英文维基百科快照的真实哈希值已添加

00:13:41.220 --> 00:13:46.440
整个语料库（约2 TB）位于IP FS节点上，

00:13:46.440 --> 00:13:50.459
散列其内容，然后您可以检索内容的任何子集，例如

00:13:50.459 --> 00:13:56.490
作为来自Wikipedia的单个页面，使用该哈希值以及其中的路径

00:13:56.490 --> 00:14:01.380
该语料库或该数据集中的路径，您可以在其中找到

00:14:01.380 --> 00:14:06.959
您想要的，就像我们之前看到的那样，您可以通过直接交互来使用它

00:14:06.959 --> 00:14:12.270
与使用IP FS API的IP FS节点一起使用，或者您可以通过HTTP Web检索它

00:14:12.270 --> 00:14:19.050
使用相同的路径和相同的标识符打开的是

00:14:19.050 --> 00:14:24.959
如果我的机器上有内容，而您却将内容固定在哪里的可能性

00:14:24.959 --> 00:14:29.579
想要将这些内容的副本保存到您的计算机上，您要执行的操作是告诉您

00:14:29.579 --> 00:14:36.240
您的IP FS节点将该哈希固定在该计算机上，这说明了

00:14:36.240 --> 00:14:40.470
节点要做的是检索与该哈希对应的内容并保留

00:14:40.470 --> 00:14:45.600
直到或除非您取消固定它并运行某种形式的

00:14:45.600 --> 00:14:53.459
垃圾收集清理之后，让我们看一下这有何影响

00:14:53.459 --> 00:14:57.930
加入访问发现和保存，例如

00:14:57.930 --> 00:15:03.060
图书馆和档案馆一直都在参与，这里的主要思想是我们可以

00:15:03.060 --> 00:15:09.329
使用固定的哈希集并将其视为集合，这使我们感到满意

00:15:09.329 --> 00:15:15.660
解决了点对点收集问题，因为该组专注于保存

00:15:15.660 --> 00:15:19.350
让我们从那里开始，第一个例子是第一个

00:15:19.350 --> 00:15:23.910
好处是复制变得容易且透明，它本身就是

00:15:23.910 --> 00:15:27.300
在保存上下文中移动数据时非常有用

00:15:27.300 --> 00:15:31.950
您有能力使用不同的存储设备或不同的存储上下文

00:15:31.950 --> 00:15:37.110
复制，然后非常轻松地验证结果，但是

00:15:37.110 --> 00:15:42.300
另一种强大的模式是下载内容的内容副本可能

00:15:42.300 --> 00:15:46.230
由您的一位顾客下载的，如果他们使用类似的模式下载

00:15:46.230 --> 00:15:51.270
ipfs或使用内容寻址方法，因为下载的副本是

00:15:51.270 --> 00:15:55.220
您可以随时通过密码验证的有效副本

00:15:55.220 --> 00:16:00.480
如果有人

00:16:00.480 --> 00:16:04.530
关心数据，他们可以将其复制到他们的计算机上，可能会告诉您

00:16:04.530 --> 00:16:12.020
他们已经复制了它，然后该副本是一个有效的有效表

00:16:12.020 --> 00:16:17.850
内容的副本可通过执行完整性检查的功能来启用

00:16:17.850 --> 00:16:21.450
自动显示在内容上，但其中有些方法

00:16:21.450 --> 00:16:24.600
这仅有益于日常的保存活动，例如

00:16:24.600 --> 00:16:28.080
内容的格式迁移和版本控制使这些事情变得容易得多

00:16:28.080 --> 00:16:33.930
当您使用内容寻址方法时，这也会影响

00:16:33.930 --> 00:16:37.680
而这会影响内容的获取的主要方式是它降低了

00:16:37.680 --> 00:16:41.760
进入壁垒或降低壁垒中内容获取的壁垒

00:16:41.760 --> 00:16:45.600
首先，它期望下一代工具的开发者

00:16:45.600 --> 00:16:49.380
在日常工作中创建和共享数据将使用诸如

00:16:49.380 --> 00:16:53.250
像Apache Spark这样的git工具已经在使用已寻址的内容

00:16:53.250 --> 00:16:58.050
的方法，但主要是它打开了这种提交的可能性

00:16:58.050 --> 00:17:03.060
无需上传，我可以简单地通知我的图书馆或计算机社区

00:17:03.060 --> 00:17:07.110
我想保留在其引脚集中的内容的哈希值的存档，并且

00:17:07.110 --> 00:17:11.760
存档可以将这些内容放入其收藏中，而无需

00:17:11.760 --> 00:17:17.700
强迫我停止工作，对我来说，顾客也变得更容易

00:17:17.700 --> 00:17:22.230
提供上下文，以使用提供我的集合的元数据上下文

00:17:22.230 --> 00:17:27.000
我认为合适的任何工具，包括提交版本系列之类的事情

00:17:27.000 --> 00:17:29.570
散列

00:17:29.850 --> 00:17:35.220
对访问也有影响，即内容复制

00:17:35.220 --> 00:17:39.179
增强了可用性，因此，如果您对该内容有尖峰和需求

00:17:39.179 --> 00:17:43.799
该系统自然会复制并增加可用数量

00:17:43.799 --> 00:17:52.110
可以用来检索内容的版本，它还允许我们执行

00:17:52.110 --> 00:17:57.450
诸如特定于内容版本之类的事情在以下情况下变得很重要

00:17:57.450 --> 00:18:04.980
人们依赖于存档中的数据的访问版本

00:18:04.980 --> 00:18:09.390
以非常有趣的方式影响发现，因此从某种意义上您可以想到它

00:18:09.390 --> 00:18:15.210
因为我们正在追踪馆藏的元数据是

00:18:15.210 --> 00:18:19.049
本身就是可以在去中心化网络上发布的数据集

00:18:19.049 --> 00:18:23.340
任何人都可以派发那个集合，他们可以执行机器分析

00:18:23.340 --> 00:18:26.580
在里士满的那个集合或元数据上，他们可以提交

00:18:26.580 --> 00:18:30.510
可以验证的结果，然后可能将其整合到

00:18:30.510 --> 00:18:35.010
主要机构维护的主要版本或正式版本，或

00:18:35.010 --> 00:18:40.169
社区维护，但您也可以从模糊

00:18:40.169 --> 00:18:44.730
机构或图书馆创建的元数据之间的界线

00:18:44.730 --> 00:18:50.059
以及由实际使用人员创建的元数据

00:18:50.059 --> 00:18:57.480
最终用户创建的元数据可以是的基础信息

00:18:57.480 --> 00:19:05.460
直接作为描述性元数据或一部分的一部分放入集合中

00:19:05.460 --> 00:19:10.380
的技术数据，并且相同的信息可以通过

00:19:10.380 --> 00:19:16.650
最终用户并重新定位并提交回去，因此我们缩小了界限

00:19:16.650 --> 00:19:20.580
在这两件事之间产生某种方式，最终以积极的方式影响发现

00:19:20.580 --> 00:19:26.480
它还提供了一种强大的内容重复数据删除方法，

00:19:26.480 --> 00:19:32.039
例如，重复数据删除和元数据重复数据删除

00:19:32.039 --> 00:19:37.080
如果我已经拥有特定信息的元数据，那么您

00:19:37.080 --> 00:19:41.820
可以请求元数据，并使用的哈希将其与内容进行匹配

00:19:41.820 --> 00:19:44.540
内容本身

00:19:44.990 --> 00:19:50.010
这是关于我们如何使用这些技术的对话的开始

00:19:50.010 --> 00:19:57.210
增强社区共享他们所依赖的数据的所有权的能力，如果

00:19:57.210 --> 00:20:01.289
您发现这些想法很有趣，或者您想要拥有，或者您想要

00:20:01.289 --> 00:20:04.950
参与有关这些技术可能走向何方的讨论

00:20:04.950 --> 00:20:08.850
一直在使用标题数据作为这些对话的占位符a

00:20:08.850 --> 00:20:11.490
许多组织已经参与其中，我们很乐意听到您的声音

00:20:11.490 --> 00:20:15.659
声音，我们不仅对了解如何将其应用于

00:20:15.659 --> 00:20:19.470
今天我们知道的网络数据，但我们也有兴趣了解如何

00:20:19.470 --> 00:20:23.850
我们可以应用这些拍子将这些模式应用到下一轮数据

00:20:23.850 --> 00:20:28.289
到达诸如物联网和数据之类的互联网

00:20:28.289 --> 00:20:32.870
正在为混合现实，增强现实和虚拟现实而制作

00:20:32.870 --> 00:20:36.570
这将在人们遇到的方式中扮演如此重要的角色

00:20:36.570 --> 00:20:41.789
未来几十年的信息，我希望您发现这些想法很有趣

00:20:41.789 --> 00:20:45.860
和鼓舞人心，我期待着您的回音

